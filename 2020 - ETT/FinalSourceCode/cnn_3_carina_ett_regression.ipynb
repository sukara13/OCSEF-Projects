{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "cnn_3_carina_ett_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfvDJADWCK1v"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow7YqilcgQey"
      },
      "source": [
        "# --- Install jarvis-md\n",
        "% pip install \\\n",
        "    --index-url https://test.pypi.org/simple/ \\\n",
        "    --extra-index-url https://pypi.org/simple \\\n",
        "    jarvis-md==0.0.1a7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CsL8PrjgQe4"
      },
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model, layers, losses, optimizers\n",
        "import os, numpy as np\n",
        "from jarvis.train.client import Client\n",
        "from jarvis.train import custom, models, datasets\n",
        "from jarvis.utils.general import overload"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ7goqm-gQe6"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL6AgiNbgQe7"
      },
      "source": [
        "datasets.download(name='xr/mimic-ett')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBuwFb28lRIm"
      },
      "source": [
        "gen_train, gen_valid, client = datasets.prepare(name='xr/mimic-ett', keyword='ett-crp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOe01PN5gQe9"
      },
      "source": [
        "### Create client and generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qogZufTUgQe-"
      },
      "source": [
        "import random\n",
        "from scipy import ndimage\n",
        "\n",
        "augEnabled = 1\n",
        "\n",
        "@overload(Client)\n",
        "def preprocess(self, arrays, **kwargs):\n",
        "  \"\"\"\n",
        "  Method to preprocess arrays\n",
        "  \"\"\"\n",
        "  # =================================================================\n",
        "  # Dynamic Augmentation\n",
        "  # =================================================================\n",
        "  # \n",
        "  # arrays['xs']['dat'] ==> cropped dat\n",
        "  # arrays['ys']['car'] ==> (z,y,x) carina or None (if not exists)\n",
        "  # arrays['ys']['ett'] ==> (z,y,x) ETT or None (if not exists)\n",
        "  # \n",
        "  # =================================================================\n",
        "\n",
        "  if augEnabled == 1:\n",
        "    # Generate a random number\n",
        "    aug = random.randint(0, 12)\n",
        "\n",
        "    \"\"\"\n",
        "    aug types:\n",
        "     0: no augmentation\n",
        "     1: zoom in (1.1)\n",
        "     2: zoom in (1.05)\n",
        "     3: zoom out (0.95)\n",
        "     4: zoom out (0.9)\n",
        "     5: shift NW (y:14, x:7)\n",
        "     6: shift NE (y:14, x:7)\n",
        "     7: shift SW (y:14, x:7)\n",
        "     8: shift SE (y:14, x:7)\n",
        "     9: shift N (y:14, x:0)\n",
        "    10: shift E (y:0, x:7)\n",
        "    11: shift S (y:14, x:0)\n",
        "    12: shift W (y:0, x:7)\n",
        "    \"\"\"\n",
        "\n",
        "    # Set dimensions\n",
        "    yDim = 256\n",
        "    xDim = 128\n",
        "\n",
        "    # Scale up or down (zoom in or out)\n",
        "    if aug > 0 and aug < 5:\n",
        "      # Remove single-dimensional entries from the image array\n",
        "      img = np.squeeze(arrays['xs']['dat']).reshape(yDim, xDim)\n",
        "\n",
        "      if aug < 3:\n",
        "        # Set scale\n",
        "        if aug == 1:\n",
        "          # Set scale to 1.1\n",
        "          scale = 1.1\n",
        "        else:\n",
        "          # Set scale to 1.05\n",
        "          scale = 1.05\n",
        "\n",
        "        # Zoom in to create a new image\n",
        "        img = ndimage.zoom(img, zoom=scale, order=1)\n",
        "\n",
        "        # Append to images in flattened form to hold in one row\n",
        "        arrays['xs']['dat'] = img[0:yDim, 0:xDim].flatten()\n",
        "      else:\n",
        "        # Set scale\n",
        "        if aug == 3:\n",
        "          # Set scale to 0.95\n",
        "          scale = 0.95\n",
        "        else:\n",
        "          # Set scale to 0.9\n",
        "          scale = 0.9\n",
        "\n",
        "        # Zoom in to create a new image\n",
        "        img = ndimage.zoom(img, zoom=scale, order=1)\n",
        "\n",
        "        # Copy into an empty yDim x xDim image\n",
        "        emptyImg = np.zeros((yDim, xDim), np.int16)\n",
        "        emptyImg[0:img.shape[0], 0:img.shape[1]] = img\n",
        "\n",
        "        # Set to flattened image\n",
        "        arrays['xs']['dat'] = emptyImg.flatten()\n",
        "\n",
        "      # Append to carina labels\n",
        "      if arrays['ys']['car'] is not None:\n",
        "        arrays['ys']['car'] = arrays['ys']['car'] * scale\n",
        "\n",
        "      # Append to ett labels\n",
        "      if arrays['ys']['ett'] is not None:\n",
        "        arrays['ys']['ett'] = arrays['ys']['ett'] * scale\n",
        "    elif aug >= 5:\n",
        "      # Remove single-dimensional entries from the image array\n",
        "      img = np.squeeze(arrays['xs']['dat']).reshape(yDim, xDim)\n",
        "\n",
        "      # Initialize translation coordinates\n",
        "      yTop = 0\n",
        "      yBottom = yDim\n",
        "      xLeft = 0\n",
        "      xRight = xDim\n",
        "\n",
        "      # Set the length of vertical and horizontal translation\n",
        "      yLen = 14 #random.randint(10, 19)\n",
        "      xLen = 7 #random.randint(10, 19)\n",
        "\n",
        "      # Set the direction of translation: up(0) and down(1); left(0) and right(1)\n",
        "      if aug == 5 or aug == 9:\n",
        "        yDir = 0\n",
        "        xDir = 0\n",
        "      elif aug == 6 or aug == 10:\n",
        "        yDir = 0\n",
        "        xDir = 1\n",
        "      elif aug == 7 or aug == 11:\n",
        "        yDir = 1\n",
        "        xDir = 0\n",
        "      elif aug == 8 or aug == 12:\n",
        "        yDir = 1\n",
        "        xDir = 1\n",
        "\n",
        "      # Set unused dimension length to zero for N, E, S, and W\n",
        "      if aug == 9 or aug == 11:\n",
        "        xLen = 0\n",
        "      elif aug == 10 or aug == 12:\n",
        "        yLen = 0\n",
        "\n",
        "      if yDir == 0: # up\n",
        "        yTop += yLen\n",
        "        newTop = 0\n",
        "        newBottom = yDim - yLen\n",
        "\n",
        "        # Append to carina labels\n",
        "        if arrays['ys']['car'] is not None:\n",
        "          arrays['ys']['car'][0][0][1] -= float(yLen / yDim)\n",
        "\n",
        "        # Append to ett labels\n",
        "        if arrays['ys']['ett'] is not None:\n",
        "          arrays['ys']['ett'][0][0][1] -= float(yLen / yDim)\n",
        "      else: # down\n",
        "        yBottom -= yLen\n",
        "        newTop = yLen\n",
        "        newBottom = yDim\n",
        "\n",
        "        # Append to carina labels\n",
        "        if arrays['ys']['car'] is not None:\n",
        "          arrays['ys']['car'][0][0][1] += float(yLen / yDim)\n",
        "\n",
        "        # Append to ett labels\n",
        "        if arrays['ys']['ett'] is not None:\n",
        "          arrays['ys']['ett'][0][0][1] += float(yLen / yDim)\n",
        "\n",
        "      if xDir == 0: # left\n",
        "        xLeft += xLen\n",
        "        newLeft = 0\n",
        "        newRight = xDim - xLen\n",
        "\n",
        "        # Append to carina labels\n",
        "        if arrays['ys']['car'] is not None:\n",
        "          arrays['ys']['car'][0][0][2] -= float(xLen / xDim)\n",
        "\n",
        "        # Append to ett labels\n",
        "        if arrays['ys']['ett'] is not None:\n",
        "          arrays['ys']['ett'][0][0][2] -= float(xLen / xDim)\n",
        "      else: # right\n",
        "        xRight -= xLen\n",
        "        newLeft = xLen\n",
        "        newRight = xDim\n",
        "\n",
        "        # Append to carina labels\n",
        "        if arrays['ys']['car'] is not None:\n",
        "          arrays['ys']['car'][0][0][2] += float(xLen / xDim)\n",
        "\n",
        "        # Append to ett labels\n",
        "        if arrays['ys']['ett'] is not None:\n",
        "          arrays['ys']['ett'][0][0][2] += float(xLen / xDim)\n",
        "\n",
        "      # Copy into an empty yDim x xDim image\n",
        "      emptyImg = np.zeros((yDim, xDim), np.int16)\n",
        "      emptyImg[newTop:newBottom, newLeft:newRight] = img[yTop:yBottom, xLeft:xRight]\n",
        "\n",
        "      # Set to flattened image\n",
        "      arrays['xs']['dat'] = emptyImg.flatten()\n",
        "\n",
        "  # =================================================================\n",
        "  # Masks\n",
        "  # =================================================================\n",
        "  for key in ['car', 'ett']:\n",
        "    if arrays['ys'][key] is None:\n",
        "      # Initialize missing data\n",
        "      arrays['ys'][key] = np.zeros((1, 1, 2, 1))\n",
        "      arrays['xs']['msk-' + key][:] = 0\n",
        "    else:\n",
        "      # Prepare pts (convert 3D to 2D)\n",
        "      arrays['ys'][key] = arrays['ys'][key][:, :, 1:]\n",
        "\n",
        "      # Prepare msk (ignore points beyond field of view)\n",
        "      arrays['xs']['msk-' + key][0] = \\\n",
        "          np.all(arrays['ys'][key] > 0, axis=(0, 2, 3), keepdims=True) & \\\n",
        "          np.all(arrays['ys'][key] < 1, axis=(0, 2, 3), keepdims=True)\n",
        "\n",
        "  return arrays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10uEPgEJgQfB"
      },
      "source": [
        "# Define configs\n",
        "configs = {'batch': {'size': 12, 'fold': -1}}\n",
        "\n",
        "# Create client\n",
        "os.environ['JARVIS_PROJECT_ID'] = 'xr/mimic-ett'\n",
        "client = Client(pattern='client-ett-crp', configs=configs)\n",
        "\n",
        "# Create generators\n",
        "gen_train, gen_valid = client.create_generators()\n",
        "\n",
        "print(client.batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5MOPSv0gQfD"
      },
      "source": [
        "# =================================================================\n",
        "# Test visualization of data batches to ensure augmentation works \n",
        "# =================================================================\n",
        "#\n",
        "# Yield one example\n",
        "xs, ys = next(gen_train)\n",
        "\n",
        "# Print dict keys\n",
        "print('xs keys: {}'.format(xs.keys()))\n",
        "print('ys keys: {}'.format(ys.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s39nrlWvnF0r"
      },
      "source": [
        "# Print data shape\n",
        "print('xs shape: {}'.format(xs['dat'].shape))\n",
        "print('xs shape: {}'.format(xs['msk-car'].shape))\n",
        "print('xs shape: {}'.format(xs['msk-ett'].shape))\n",
        "print('ys shape: {}'.format(ys['car'].shape))\n",
        "print('ys shape: {}'.format(ys['ett'].shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Py9khdpnFjM"
      },
      "source": [
        "from jarvis.utils.display import imshow\n",
        "\n",
        "# --- Show the first example\n",
        "imshow(xs['dat'][0, 0])\n",
        "\n",
        "# --- Show \"montage\" of all images\n",
        "imshow(xs['dat'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50C0O268gQfG"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RJryC_HgQfH"
      },
      "source": [
        "def prepare_model(inputs):\n",
        "    # --- Get blocks\n",
        "    kwargs = models.create_block_components(names=('kwargs_z1',))[0]\n",
        "    conv1, conv2 = models.create_blocks(('conv1', 'conv2'))\n",
        "\n",
        "    # --- Define layers\n",
        "    l1 = conv2(48, conv1(48, conv1(48, conv1(48, conv1(48, conv1(48, inputs['dat']))))))\n",
        "    l2 = conv2(56, conv1(56, conv1(56, conv1(56, conv1(56, l1)))))\n",
        "    l3 = conv2(64, conv1(64, conv1(64, conv1(64, conv1(64, l2)))))\n",
        "    l4 = conv2(80, conv1(80, conv1(80, conv1(80, l3))))\n",
        "    l5 = conv2(96, conv1(96, conv1(96, conv1(96, l4))))\n",
        "    l6 = conv2(112, conv1(112, conv1(112, l5)))\n",
        "    l7 = conv2(128, conv1(128, conv1(128, l6)))\n",
        "\n",
        "    # --- Flatten\n",
        "    c1 = layers.Reshape((1, 1, 1, 2 * 1 * 128))(l7)\n",
        "    c2 = layers.Conv3D(filters=2, kernel_size=(1, 1, 1), activation='sigmoid')(c1)\n",
        "    c3 = layers.Conv3D(filters=2, kernel_size=(1, 1, 1), activation='sigmoid')(c1)\n",
        "    \n",
        "    # --- Create logits\n",
        "    logits = {}\n",
        "    logits['car'] = layers.Reshape((-1, 1, 2, 1), name='car')(c2)\n",
        "    logits['ett'] = layers.Reshape((-1, 1, 2, 1), name='ett')(c3)\n",
        "\n",
        "    # --- Create model\n",
        "    model = Model(inputs=inputs, outputs=logits) \n",
        "\n",
        "    # --- Compile the model\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "        loss={\n",
        "            'car': custom.mse(inputs['msk-car']), \n",
        "            'ett': custom.mse(inputs['msk-ett'])})\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9OwqpEggQfN"
      },
      "source": [
        "### Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKHO3a5295t7"
      },
      "source": [
        "import math\n",
        "import datetime\n",
        "\n",
        "def test_model(fold):\n",
        "  # Set start time\n",
        "  startTime = datetime.datetime.now().time()\n",
        "\n",
        "  # Initialize total count\n",
        "  cntTotal = 0\n",
        "\n",
        "  # --- Create client\n",
        "  test_train, test_valid = client.create_generators(test=True)\n",
        "\n",
        "  cntCar = 0\n",
        "  cntEtt = 0\n",
        "  distInPixelsCar = 0\n",
        "  distInPixelsEtt = 0\n",
        "\n",
        "  # Calculate the distance between lables and predictions\n",
        "  for x, y in test_valid:\n",
        "    logits = model.predict(x)\n",
        "\n",
        "    # Get carina and ETT labels\n",
        "    labelCarY = y['car'].flatten()[0]*256\n",
        "    labelCarX = y['car'].flatten()[1]*128\n",
        "    labelEttY = y['ett'].flatten()[0]*256\n",
        "    labelEttX = y['ett'].flatten()[1]*128\n",
        "\n",
        "    # Get carina and ETT predictions\n",
        "    predCarY = logits[0].flatten()[0]*256\n",
        "    predCarX = logits[0].flatten()[1]*128\n",
        "    predEttY = logits[1].flatten()[0]*256\n",
        "    predEttX = logits[1].flatten()[1]*128\n",
        "\n",
        "    # Calculate distance between label and prediction for carina\n",
        "    carExists = 0\n",
        "    if labelCarY > 0 and labelCarX > 0:\n",
        "      carExists = 1\n",
        "      cntCar += 1\n",
        "      distInPixels = math.sqrt((predCarY - labelCarY) ** 2 + (predCarX - labelCarX) ** 2)\n",
        "      distInPixelsCar += distInPixels\n",
        "      with open('carina_distances.csv', 'a') as carDistFile:\n",
        "        carDistFile.write(str(fold) + ',' + str(distInPixels) + '\\n')\n",
        "\n",
        "    # Calculate distance between label and prediction for ETT\n",
        "    ettExists = 0\n",
        "    if labelEttY > 0 and labelEttX > 0:\n",
        "      ettExists = 1\n",
        "      cntEtt += 1\n",
        "      distInPixels = math.sqrt((predEttY - labelEttY) ** 2 + (predEttX - labelEttX) ** 2)\n",
        "      distInPixelsEtt += distInPixels\n",
        "      with open('ett_distances.csv', 'a') as ettDistFile:\n",
        "        ettDistFile.write(str(fold) + ',' + str(distInPixels) + '\\n')\n",
        "\n",
        "    if carExists == 1 and ettExists == 1:\n",
        "      with open('car_ett_distances.csv', 'a') as ettDistFile:\n",
        "        ettDistFile.write(str(fold) + ',' + str(labelCarY) + ',' + str(labelCarX) + ',' + str(labelEttY) + ',' + str(labelEttX) + ',' + str(predCarY) + ',' + str(predCarX) + ',' + str(predEttY) + ',' + str(predEttX) + '\\n')\n",
        "\n",
        "    cntTotal += 1\n",
        "\n",
        "  # Set end time\n",
        "  endTime = datetime.datetime.now().time()\n",
        "\n",
        "  # Print start and end times\n",
        "  print(\"Start Time: \" + str(startTime))\n",
        "  print(\"End Time: \" + str(endTime))\n",
        "  print(\"Item Count: \" + str(cntTotal) + '\\n')\n",
        "\n",
        "  # Display test results\n",
        "  print('\\n\\nCarina Count: ' + str(cntCar))\n",
        "  print('Carina Avg Dist in Pixels: ' + str(distInPixelsCar / cntCar))\n",
        "  print('Carina Avg Dist in Cm: ' + str(distInPixelsCar * 0.08 / cntCar))\n",
        "  print('\\nETT Count: ' + str(cntEtt))\n",
        "  print('ETT Avg Dist in Pixels: ' + str(distInPixelsEtt / cntEtt))\n",
        "  print('ETT Avg Dist in Cm: ' + str(distInPixelsEtt * 0.08 / cntEtt) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDRYJCxsg770"
      },
      "source": [
        "#--------------------------------------------\n",
        "# Train and test with 5-fold cross validation\n",
        "#--------------------------------------------\n",
        "\n",
        "with open('carina_distances.csv', 'a') as carDistFile:\n",
        "  carDistFile.write('fold,dist\\n')\n",
        "with open('ett_distances.csv', 'a') as ettDistFile:\n",
        "  ettDistFile.write('fold,dist\\n')\n",
        "with open('car_ett_distances.csv', 'a') as carEttDistFile:\n",
        "  carEttDistFile.write('fold,car_label_y,car_label_x,ett_label_y,ett_label_x,car_pred_y,car_pred_x,ett_pred_y,ett_pred_x\\n')\n",
        "\n",
        "for fold in range(5):\n",
        "  print('fold: ' + str(fold))\n",
        "\n",
        "  # Set fold\n",
        "  configs = {'batch': {'size': 12, 'fold': fold}}\n",
        "\n",
        "  # --- Create client\n",
        "  os.environ['JARVIS_PROJECT_ID'] = 'xr/mimic-ett'\n",
        "  client = Client(pattern='client-ett-crp', configs=configs)\n",
        "\n",
        "  # --- Create generators\n",
        "  gen_train, gen_valid = client.create_generators()\n",
        "\n",
        "  # Get inputs\n",
        "  inputs = client.get_inputs(Input)\n",
        "\n",
        "  # Prepare the model\n",
        "  model = prepare_model(inputs)\n",
        "\n",
        "  # Load data into memory for faster training\n",
        "  client.load_data_in_memory()\n",
        "\n",
        "  # Initialize learning rate and epoch\n",
        "  lr = 0.0005\n",
        "  epoch = 1\n",
        "\n",
        "  # Augmentation enabled\n",
        "  augEnabled = 1 # change random start from 1 to 0 in preprocess\n",
        "\n",
        "  for j in range(2):\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=lr),\n",
        "        loss={\n",
        "            'car': custom.mse(inputs['msk-car']), \n",
        "            'ett': custom.mse(inputs['msk-ett'])})\n",
        "\n",
        "    for i in range(3):\n",
        "      print('learning-rate: ' + str(lr))\n",
        "      print('epoch: ' + str(epoch))\n",
        "\n",
        "      # Train the model\n",
        "      model.fit(\n",
        "          x=gen_train,\n",
        "          steps_per_epoch=6500, # (6000 training items / 12 batch size) x (1 + 12 augmentations)\n",
        "          epochs=1,\n",
        "          validation_data=gen_valid,\n",
        "          validation_steps=6500,\n",
        "          validation_freq=1)\n",
        "\n",
        "      # Increment epoch\n",
        "      epoch += 1\n",
        "\n",
        "      # Check epoch to break the loop\n",
        "      if epoch == 5:\n",
        "        break\n",
        "\n",
        "    # Check epoch to break the loop\n",
        "    if epoch == 5:\n",
        "      break\n",
        "\n",
        "    # Divide learning rate by 10\n",
        "    lr /= 10\n",
        "\n",
        "  # Test the model\n",
        "  test_model(fold)\n",
        "\n",
        "  # Delete the model at the end of each fold\n",
        "  del model\n",
        "\n",
        "!cp ./carina_distances.csv '/content/drive/My Drive/Colab Notebooks/carina_distances.csv'\n",
        "!cp ./ett_distances.csv '/content/drive/My Drive/Colab Notebooks/ett_distances.csv'\n",
        "!cp ./car_ett_distances.csv '/content/drive/My Drive/Colab Notebooks/car_ett_distances.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZACCmSfzkit"
      },
      "source": [
        "#--------------------------------------------------\n",
        "# Generate a model file from the whole training set\n",
        "#--------------------------------------------------\n",
        "\n",
        "# Set fold to -1\n",
        "configs = {'batch': {'size': 12, 'fold': -1}}\n",
        "\n",
        "# --- Create client\n",
        "os.environ['JARVIS_PROJECT_ID'] = 'xr/mimic-ett'\n",
        "client = Client(pattern='client-ett-crp', configs=configs)\n",
        "\n",
        "# --- Create generators\n",
        "gen_train, gen_valid = client.create_generators()\n",
        "\n",
        "# Get inputs\n",
        "inputs = client.get_inputs(Input)\n",
        "\n",
        "# Prepare the model\n",
        "model = prepare_model(inputs)\n",
        "\n",
        "# Load data into memory for faster training\n",
        "client.load_data_in_memory()\n",
        "\n",
        "# Initialize learning rate and epoch\n",
        "lr = 0.0005\n",
        "epoch = 1\n",
        "\n",
        "for j in range(2):\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      optimizer=optimizers.Adam(learning_rate=lr),\n",
        "      loss={\n",
        "          'car': custom.mse(inputs['msk-car']), \n",
        "          'ett': custom.mse(inputs['msk-ett'])})\n",
        "\n",
        "  for i in range(3):\n",
        "    print('learning-rate: ' + str(lr))\n",
        "    print('epoch: ' + str(epoch))\n",
        "\n",
        "    # Augmentation enabled\n",
        "    augEnabled = 1 # change random start from 0 to 1 in preprocess\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x=gen_train,\n",
        "        steps_per_epoch=7500, # (7500 training items / 12 batch size) x (12 augmentations)\n",
        "        epochs=1,\n",
        "        validation_data=gen_valid,\n",
        "        validation_steps=7500,\n",
        "        validation_freq=1)\n",
        "\n",
        "    # Increment epoch\n",
        "    epoch += 1\n",
        "\n",
        "    # Check epoch to break the loop\n",
        "    if epoch == 5:\n",
        "      break\n",
        "\n",
        "  # Check epoch to break the loop\n",
        "  if epoch == 5:\n",
        "    break\n",
        "\n",
        "  # Divide learning rate by 10\n",
        "  lr /= 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXQvjee3q7eC"
      },
      "source": [
        "# --- Save the model to a file\n",
        "model.save('./cnn_3_carina_ett_regression.hdf5')\n",
        "\n",
        "# Copy the model to google drive\n",
        "!cp ./cnn_3_carina_ett_regression.hdf5 '/content/drive/My Drive/Colab Notebooks/cnn_3_carina_ett_regression.hdf5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xrfJxzzxFR5"
      },
      "source": [
        "# Copy the model file from google drive\n",
        "!cp '/content/drive/My Drive/Colab Notebooks/cnn_3_carina_ett_regression.hdf5' ./cnn_3_carina_ett_regression.hdf5\n",
        "\n",
        "# Load the model from the file\n",
        "from tensorflow.keras import models as tfModels\n",
        "model = tfModels.load_model('./cnn_3_carina_ett_regression.hdf5', compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie8_8tz3IhII"
      },
      "source": [
        "# Calculate distance from ETT to carina on all ETT positive images and compare with the values in ett.csv\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Initialize global variables\n",
        "count = 0\n",
        "totalError = 0\n",
        "ettBelowCarina = 0\n",
        "\n",
        "# Initialize input date\n",
        "xs= {}\n",
        "xs['dat'] = np.zeros((1, 1, 256, 128, 1))\n",
        "xs['msk-car'] = np.zeros((1, 1, 1, 2, 1))\n",
        "xs['msk-ett'] = np.zeros((1, 1, 1, 2, 1))\n",
        "\n",
        "# Read the contents of the cxr-record-list file\n",
        "with open(\"./cxr-record-list.csv\", 'r') as recFile:\n",
        "  recContent = recFile.read()\n",
        "\n",
        "# Read the contents of the true negative file\n",
        "with open(\"./trueNeg.csv\", 'r') as trueNegFile:\n",
        "  trueNegContent = trueNegFile.read()\n",
        "\n",
        "# Read the contents of the ett file\n",
        "with open(\"./ett.csv\", 'r') as ettFile:\n",
        "  ettContent = ettFile.read()\n",
        "\n",
        "# Read the contents of the frontal file\n",
        "with open(\"./db-mimic-frontal-only.csv\", 'r') as frontalFile:\n",
        "  imgNames = frontalFile.readlines()\n",
        "\n",
        "# Process each frontal image\n",
        "for imgName in imgNames:\n",
        "  # Strip whitespaces\n",
        "  imgName = imgName.strip()\n",
        "\n",
        "  # Search for the image name in cxr-record-list\n",
        "  imgStart = recContent.find(imgName + \".dcm\")\n",
        "\n",
        "  # Get patient ID\n",
        "  patientID = recContent[imgStart-19:imgStart-11]\n",
        "\n",
        "  # Get study ID\n",
        "  studyID = recContent[imgStart-9:imgStart-1]\n",
        "\n",
        "  # Get folder\n",
        "  folder = recContent[imgStart-23:imgStart-21]\n",
        "\n",
        "  # Search for the study in ETT file\n",
        "  patientStart = ettContent.find(patientID + \",\" + studyID)\n",
        "  if patientStart != -1:\n",
        "    # Search for the image in true negative file\n",
        "    imgStart = trueNegContent.find(imgName)\n",
        "    if imgStart != -1:\n",
        "      patientStart = -1\n",
        "\n",
        "  # Patient and study not found in ett\n",
        "  if patientStart == -1:\n",
        "    continue\n",
        "\n",
        "  # Search for new line at the end of distance\n",
        "  newLinePos = ettContent.find(\"\\n\", patientStart)\n",
        "\n",
        "  # Get distance to carina from ett\n",
        "  distToCarinaLabel = float(ettContent[patientStart+52:newLinePos])\n",
        "  \n",
        "  # Set path\n",
        "  imgFile = \"./crops/p\" + folder + \"/p\" + patientID + \"/s\" + studyID + \"/\" + imgName + \".npy\"\n",
        "\n",
        "  # Load an image file\n",
        "  imgS = np.load(imgFile)\n",
        "\n",
        "  # Normalize the image\n",
        "  imgN = (imgS - np.mean(imgS)) / np.std(imgS)\n",
        "\n",
        "  # Predict coordinates of carina and ett on the 256x128 cropped image\n",
        "  xs['dat'] = imgN.reshape(1, 1, 256, 128, 1)\n",
        "  logits = model.predict(x=xs)\n",
        "\n",
        "  # Get carina and ETT predictions\n",
        "  predCarY = logits[0].flatten()[0]*256\n",
        "  predCarX = logits[0].flatten()[1]*128\n",
        "  predEttY = logits[1].flatten()[0]*256\n",
        "  predEttX = logits[1].flatten()[1]*128\n",
        "\n",
        "  # Calculate distance from ett to carina\n",
        "  distToCarinaPred = math.sqrt(((predCarY - predEttY) ** 2) + ((predCarX - predEttX) ** 2)) * 0.08\n",
        "\n",
        "  # Check whether ett is below carina\n",
        "  if predEttY > predCarY:\n",
        "    ettBelowCarina += 1\n",
        "    \n",
        "  # Add error\n",
        "  totalError += abs(distToCarinaLabel - distToCarinaPred)\n",
        "\n",
        "  # Append distance to a file to calculate median\n",
        "  with open('ett_rpt_distances.csv', 'a') as ettRptDistFile:\n",
        "    ettRptDistFile.write(str(abs(distToCarinaLabel - distToCarinaPred)) + '\\n')\n",
        "\n",
        "  # Increment count\n",
        "  count += 1\n",
        "\n",
        "# Print calculations\n",
        "print(\"Total error: \" + str(totalError))\n",
        "print(\"Total count: \" + str(count))\n",
        "print(\"Average error: \" + str(totalError / count))\n",
        "print(\"ETT below carina: \" + str(ettBelowCarina))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}